{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-19T13:22:39.275632Z","iopub.status.busy":"2021-11-19T13:22:39.275392Z","iopub.status.idle":"2021-11-19T13:22:45.304089Z","shell.execute_reply":"2021-11-19T13:22:45.303210Z","shell.execute_reply.started":"2021-11-19T13:22:39.275559Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from tqdm import tqdm\n","import gc\n","\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from transformers import AutoTokenizer, AutoModel, AdamW\n","\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/bin/sh: nvidia-smi: 未找到命令\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:45.308634Z","iopub.status.busy":"2021-11-19T13:22:45.308313Z","iopub.status.idle":"2021-11-19T13:22:45.792513Z","shell.execute_reply":"2021-11-19T13:22:45.791748Z","shell.execute_reply.started":"2021-11-19T13:22:45.308597Z"},"trusted":true},"outputs":[],"source":["#数据分析预处理\n","df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\")\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["预处理方式\n","1. 特殊符号过滤\n","2. 大小写\n","3. 停用词"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:45.793950Z","iopub.status.busy":"2021-11-19T13:22:45.793663Z","iopub.status.idle":"2021-11-19T13:22:45.800567Z","shell.execute_reply":"2021-11-19T13:22:45.799514Z","shell.execute_reply.started":"2021-11-19T13:22:45.793914Z"},"trusted":true},"outputs":[],"source":["def special_filter():\n","    pass\n","def lowercase():\n","    pass\n","def stop_word():\n","    pass\n","def no_action():\n","    pass\n","#baseline 不做预处理\n","no_action()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:45.803363Z","iopub.status.busy":"2021-11-19T13:22:45.802976Z","iopub.status.idle":"2021-11-19T13:22:46.249415Z","shell.execute_reply":"2021-11-19T13:22:46.248762Z","shell.execute_reply.started":"2021-11-19T13:22:45.803325Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","#数据分析\n","#句子长度统计\n","sentences = list(set(df['less_toxic'].values.tolist()+df['more_toxic'].values.tolist()))\n","print(len(sentences))\n","\n","sen_lengths = [len(i) for i in sentences]\n","plt.hist(sen_lengths,bins = 100)\n","plt.show()\n","\n","# 去除过长的数据"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.250944Z","iopub.status.busy":"2021-11-19T13:22:46.250519Z","iopub.status.idle":"2021-11-19T13:22:46.258360Z","shell.execute_reply":"2021-11-19T13:22:46.257703Z","shell.execute_reply.started":"2021-11-19T13:22:46.250906Z"},"trusted":true},"outputs":[],"source":["sentences[-1]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.259941Z","iopub.status.busy":"2021-11-19T13:22:46.259649Z","iopub.status.idle":"2021-11-19T13:22:46.283934Z","shell.execute_reply":"2021-11-19T13:22:46.283261Z","shell.execute_reply.started":"2021-11-19T13:22:46.259905Z"},"trusted":true},"outputs":[],"source":["#训练集和测试集分割\n","train_data = df.sample(frac=0.9,random_state=200) #random state is a seed value\n","test_data = df.drop(train_data.index)\n","print(train_data.shape)\n","print(test_data.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.285310Z","iopub.status.busy":"2021-11-19T13:22:46.285056Z","iopub.status.idle":"2021-11-19T13:22:46.296155Z","shell.execute_reply":"2021-11-19T13:22:46.295232Z","shell.execute_reply.started":"2021-11-19T13:22:46.285274Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = max_length\n","        self.tokenizer = tokenizer\n","        self.more_toxic = df['more_toxic'].values\n","        self.less_toxic = df['less_toxic'].values\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        more_toxic = self.more_toxic[index]\n","        less_toxic = self.less_toxic[index]\n","        inputs_more_toxic = self.tokenizer.encode_plus(\n","                                more_toxic,\n","                                truncation=True,\n","                                add_special_tokens=True,\n","                                max_length=self.max_len,\n","                                padding='max_length'\n","                            )\n","        inputs_less_toxic = self.tokenizer.encode_plus(\n","                                less_toxic,\n","                                truncation=True,\n","                                add_special_tokens=True,\n","                                max_length=self.max_len,\n","                                padding='max_length'\n","                            )\n","        target = 1\n","        \n","        more_toxic_ids = inputs_more_toxic['input_ids']\n","        more_toxic_mask = inputs_more_toxic['attention_mask']\n","        \n","        less_toxic_ids = inputs_less_toxic['input_ids']\n","        less_toxic_mask = inputs_less_toxic['attention_mask']\n","        \n","        \n","        return {\n","            'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n","            'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n","            'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n","            'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n","            'target': torch.tensor(target, dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.297960Z","iopub.status.busy":"2021-11-19T13:22:46.297667Z","iopub.status.idle":"2021-11-19T13:22:46.309291Z","shell.execute_reply":"2021-11-19T13:22:46.308587Z","shell.execute_reply.started":"2021-11-19T13:22:46.297926Z"},"trusted":true},"outputs":[],"source":["class MyModel(nn.Module):\n","    def __init__(self, config):\n","        super(MyModel, self).__init__()\n","        self.model = AutoModel.from_pretrained(config.model_name)\n","        self.drop = nn.Dropout(p=config.dropout)\n","        self.fc = nn.Linear(config.hidden_dim,config.num_labels)\n","        \n","    def forward(self, ids, mask):        \n","        out = self.model(input_ids=ids,attention_mask=mask)\n","        out = self.drop(out[1])\n","        outputs = self.fc(out)\n","        return outputs"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.311041Z","iopub.status.busy":"2021-11-19T13:22:46.310674Z","iopub.status.idle":"2021-11-19T13:22:46.321481Z","shell.execute_reply":"2021-11-19T13:22:46.320795Z","shell.execute_reply.started":"2021-11-19T13:22:46.311008Z"},"trusted":true},"outputs":[],"source":["def criterion(outputs1, outputs2, targets):\n","    return (outputs1, outputs2, targets)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.325920Z","iopub.status.busy":"2021-11-19T13:22:46.324808Z","iopub.status.idle":"2021-11-19T13:22:46.336436Z","shell.execute_reply":"2021-11-19T13:22:46.335659Z","shell.execute_reply.started":"2021-11-19T13:22:46.325877Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(model,config, optimizer, criterion,scheduler, dataloader, device, epoch):\n","    model.train()\n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.long)\n","        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.long)\n","        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.long)\n","        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","        \n","        batch_size = more_toxic_ids.size(0)\n","\n","        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n","        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n","        \n","        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n","        loss = loss / config.n_accumulate\n","        loss.backward()\n","    \n","        if (step + 1) % config.n_accumulate == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","                \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.338523Z","iopub.status.busy":"2021-11-19T13:22:46.337786Z","iopub.status.idle":"2021-11-19T13:22:46.350336Z","shell.execute_reply":"2021-11-19T13:22:46.349465Z","shell.execute_reply.started":"2021-11-19T13:22:46.338488Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def test_one_epoch(model,criterion,dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    right = 0\n","    total = 0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.long)\n","        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.long)\n","        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.long)\n","        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","        \n","        batch_size = more_toxic_ids.size(0)\n","\n","        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n","        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n","        right += (more_toxic_outputs>less_toxic_outputs).sum()\n","        total += batch_size \n","        \n","        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])   \n","        \n","    print(\"acc:{}\".format(right/total))\n","    \n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.352052Z","iopub.status.busy":"2021-11-19T13:22:46.351482Z","iopub.status.idle":"2021-11-19T13:22:46.364891Z","shell.execute_reply":"2021-11-19T13:22:46.364037Z","shell.execute_reply.started":"2021-11-19T13:22:46.352015Z"},"trusted":true},"outputs":[],"source":["from dataclasses import dataclass\n","\n","@dataclass\n","class Config:\n","    \"\"\"train config\"\"\"\n","    model_name: str = \"bert-base-cased\"\n","    hidden_dim: int = 768\n","    max_length: int = 512\n","    dropout: float = 0.3\n","    num_labels: int = 1\n","    lr: float = 0.001\n","    epoch: int = 2\n","    n_accumulate: int = 1\n","    weight_decay: float = 1e-6\n","config = Config()\n","config"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:22:46.366877Z","iopub.status.busy":"2021-11-19T13:22:46.366541Z","iopub.status.idle":"2021-11-19T13:22:47.040422Z","shell.execute_reply":"2021-11-19T13:22:47.039460Z","shell.execute_reply.started":"2021-11-19T13:22:46.366831Z"},"trusted":true},"outputs":[],"source":["!CUDA_LAUNCH_BLOCKING=1"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:23:04.386136Z","iopub.status.busy":"2021-11-19T13:23:04.385293Z","iopub.status.idle":"2021-11-19T13:23:36.391031Z","shell.execute_reply":"2021-11-19T13:23:36.389664Z","shell.execute_reply.started":"2021-11-19T13:23:04.386085Z"},"trusted":true},"outputs":[],"source":["#train!\n","\n","# def train_one_epoch(model, config,optimizer,criterion, scheduler, dataloader, device, epoch)\n","# def test_one_epoch(model, criterion,dataloader, device, epoch):\n","tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n","model = MyModel(config)\n","criterion = nn.MarginRankingLoss(margin=0.5)\n","optimizer = AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","scheduler = None\n","#class MyDataset(Dataset):\n","#     def __init__(self, df, tokenizer, max_length)\n","tmp_train_data = train_data.sample(frac=0.01,random_state=200)\n","train_loader = DataLoader(MyDataset(tmp_train_data,tokenizer,config.max_length),batch_size=16,shuffle=True)\n","test_loader = DataLoader(MyDataset(tmp_train_data,tokenizer,config.max_length),batch_size=16)\n","\n","model.to(device)\n","\n","for i in range(config.epoch):\n","    train_one_epoch(model,config,optimizer,criterion,scheduler,train_loader,device,i)\n","    test_one_epoch(model,criterion,test_loader,device,i)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T13:13:59.082578Z","iopub.status.busy":"2021-11-19T13:13:59.082314Z","iopub.status.idle":"2021-11-19T13:13:59.881406Z","shell.execute_reply":"2021-11-19T13:13:59.880413Z","shell.execute_reply.started":"2021-11-19T13:13:59.082535Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-11-19T08:46:56.423576Z","iopub.status.busy":"2021-11-19T08:46:56.423294Z","iopub.status.idle":"2021-11-19T08:47:04.861757Z","shell.execute_reply":"2021-11-19T08:47:04.860897Z","shell.execute_reply.started":"2021-11-19T08:46:56.423539Z"}},"source":["# !pip install GPUtil\n","\n","import torch\n","from GPUtil import showUtilization as gpu_usage\n","from numba import cuda\n","\n","def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()                             \n","\n","    torch.cuda.empty_cache()\n","\n","    cuda.select_device(0)\n","    cuda.close()\n","    cuda.select_device(0)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()\n","\n","free_gpu_cache()    "]},{"cell_type":"markdown","metadata":{},"source":["|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   15011 MB |   15107 MB |   23364 MB |    8352 MB |\\n|       from large pool |   15008 MB |   15104 MB |   23360 MB |    8352 MB |\\n|       from small pool |       3 MB |       3 MB |       3 MB |       0 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   15011 MB |   15107 MB |   23364 MB |    8352 MB |\\n|       from large pool |   15008 MB |   15104 MB |   23360 MB |    8352 MB |\\n|       from small pool |       3 MB |       3 MB |       3 MB |       0 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   15076 MB |   15172 MB |   15172 MB |   98304 KB |\\n|       from large pool |   15072 MB |   15168 MB |   15168 MB |   98304 KB |\\n|       from small pool |       4 MB |       4 MB |       4 MB |       0 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   66135 KB |   79575 KB |  415431 KB |  349295 KB |\\n|       from large pool |   65280 KB |   77568 KB |  410618 KB |  345338 KB |\\n|       from small pool |     855 KB |    2045 KB |    4813 KB |    3957 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     358    |     360    |     444    |      86    |\\n|       from large pool |     193    |     195    |     269    |      76    |\\n|       from small pool |     165    |     165    |     175    |      10    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     358    |     360    |     444    |      86    |\\n|       from large pool |     193    |     195    |     269    |      76    |\\n|       from small pool |     165    |     165    |     175    |      10    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     129    |     131    |     131    |       2    |\\n|       from large pool |     127    |     129    |     129    |       2    |\\n|       from small pool |       2    |       2    |       2    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      21    |      22    |      30    |       9    |\\n|       from large pool |      19    |      19    |      23    |       4    |\\n|       from small pool |       2    |       4    |       7    |       5    |\\n|===========================================================================|\\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i in range(10):\n","    train_one_epoch(model,config,optimizer,criterion,scheduler,train_loader,device,i)\n","    test_one_epoch(model,criterion,test_loader,device,i)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["right = 0\n","total = 0\n","for step, data in enumerate(train_loader):\n","    more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.long)\n","    more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.long)\n","    less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.long)\n","    less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.long)\n","    targets = data['target'].to(device, dtype=torch.long)\n","        \n","    batch_size = more_toxic_ids.size(0)\n","    print(batch_size)\n","\n","    more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n","    print(more_toxic_outputs)\n","    less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n","    print(less_toxic_outputs)\n","    right += (more_toxic_outputs>less_toxic_outputs).sum()\n","    print(right)\n","    total += batch_size \n","        \n","    loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n","    print(loss)\n","    break"]}],"metadata":{"interpreter":{"hash":"4c5a227d793cc73bd86fab0339308685bc699009facaf7efba5b11c0193b5c6a"},"kernelspec":{"display_name":"Python 3.7.0 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":4}
